{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import config\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'image_predictions.tsv'\n",
    "path = Path(path_to_file)\n",
    "\n",
    "if not path.is_file():\n",
    "\n",
    "    images_data = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')\n",
    "    images_data.close()\n",
    "\n",
    "\n",
    "    with open('image_predictions.tsv', 'wb') as f:\n",
    "        f.write(images_data.content)\n",
    "    f.close()\n",
    "\n",
    "image_preds = pd.read_csv('image_predictions.tsv', sep='\\t')\n",
    "image_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(config.CONSUMER_KEY, config.CONSUMER_SECRET)\n",
    "auth.set_access_token(config.ACCESS_TOKEN, config.ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "path_to_file = 'tweet_json.txt'\n",
    "path = Path(path_to_file)\n",
    "\n",
    "if not path.is_file():\n",
    "\n",
    "    tweet_ids = tweets_df.tweet_id.values \n",
    "\n",
    "    count = 0\n",
    "    fails_dict = {}\n",
    "    start = time.time()\n",
    "    with open('tweet_json.txt', 'w') as outfile:\n",
    "        for tweet_id in tweet_ids:\n",
    "            count += 1\n",
    "            print(str(count) + \": \" + str(tweet_id))\n",
    "            try:\n",
    "                tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "                print(\"Success\")\n",
    "                json.dump(tweet._json, outfile)\n",
    "                outfile.write('\\n')\n",
    "            except tweepy.errors.HTTPException as e:\n",
    "                print(\"Fail\")\n",
    "                fails_dict[tweet_id] = e\n",
    "                pass\n",
    "    print(fails_dict)\n",
    "    print('\\n')\n",
    "    print('time elapsed: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_df = pd.read_json('tweet_json.txt', lines=True)\n",
    "retweets_df = retweets_df[['created_at', 'id', 'retweet_count', 'favorite_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.name.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds[(image_preds.p1_dog != True) & (image_preds.p2_dog != True) & (image_preds.p3_dog != True)]\n",
    "# records of invalid dog images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1. `tweets_df`: `timestamp` column is a pandas object datatype instead of a datetime datatype\n",
    "\n",
    "2. `tweets_df`: retweets rows and columns found in this tweets dataset\n",
    "\n",
    "2. `tweets_df`: Stop words like *a, the, ..* found in `name`\n",
    "\n",
    "3. `tweets_df`: Nulls represented as *None* in `name`\n",
    "\n",
    "4. `tweets_df`: Nulls represented as *None* in `doggo, floofer, pupper & puppo`\n",
    "\n",
    "5. `tweets_df`: `rating_denominator` has incorrect values which include numbers < 10 (also the number 11 is incorrect)\n",
    "\n",
    "6. `tweets_df`: The `text` column serves as redundant data\n",
    "\n",
    "7. `image_preds`: Inconsistent capitilization of names in `p1, p2 & p3` (some name of dog types begin with lower case).\n",
    "\n",
    "8. `image_preds`: columns `p1_dog, p2_dog, p3_dog` have records in which all are false, making them invalid dog type images.\n",
    "\n",
    "9. `retweets_df`: `id` column instead of *twitter_id* column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1. Dog stages represented in 4 columns instead of 1 in `tweets_df`\n",
    "\n",
    "2. Only most confident predicted image column is needed in `image_preds`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy = tweets_df.copy()\n",
    "retweet_df_copy = retweets_df.copy()\n",
    "image_preds_copy = image_preds.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Change timestamp to datatime datatype using pandas `to_datetime` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.timestamp = pd.to_datetime(tweets_df_copy.timestamp)\n",
    "#changing timestamp to datetime datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "Delete rows and columns with retweet information using pandas `iloc` and `drop` methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy = tweets_df_copy[tweets_df_copy.retweeted_status_id.isnull()]\n",
    "tweets_df_copy = tweets_df_copy[tweets_df_copy.in_reply_to_status_id.isnull()]\n",
    "tweets_df_copy.drop(['in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis=1, inplace=True)\n",
    "\n",
    "# dropping off retweet records and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace stop words with `np.nan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_names(tweets):\n",
    "    \"\"\"\n",
    "    Replaces stop words with NaN\n",
    "    \n",
    "    Arguments:\n",
    "        tweets: a dataframe\n",
    "\n",
    "    Returns:\n",
    "        null values inplace of stop words in the name column\n",
    "    \"\"\"\n",
    "\n",
    "    if tweets['name'][0].islower():\n",
    "        new_name = np.nan\n",
    "        return new_name\n",
    "    else:\n",
    "        return tweets['name']\n",
    "\n",
    "tweets_df_copy.name = tweets_df_copy.apply(replace_names, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.name.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace None with `np.nan` in `name` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.name.replace('None', np.nan, inplace=True)\n",
    "# replaces None with null value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace Nulls with `np.nan` in columns `doggo, floofer, pupper & puppo`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.doggo.replace('None', np.nan, inplace=True)\n",
    "tweets_df_copy.floofer.replace('None', np.nan, inplace=True)\n",
    "tweets_df_copy.pupper.replace('None', np.nan, inplace=True)\n",
    "tweets_df_copy.puppo.replace('None', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tweets_df_copy.doggo.values == 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace values less than 10 and which are 11 in the `rating_denominator` column with 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(tweets):\n",
    "\n",
    "    \"\"\" \n",
    "    Replaces values less than 10 with 10\n",
    "\n",
    "    Arguments:\n",
    "        tweets: a dataframe\n",
    "\n",
    "    Returns:\n",
    "        10 for values less than 10 in the rating_denominator column\n",
    "    \"\"\"\n",
    "\n",
    "    if tweets['rating_denominator'] < 10:\n",
    "        new_value = 10\n",
    "        return new_value\n",
    "    else:\n",
    "        return tweets['rating_denominator']\n",
    "\n",
    "tweets_df_copy['rating_denominator'] = tweets_df_copy.apply(replace_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy = tweets_df_copy[tweets_df_copy.rating_denominator !=11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy[(tweets_df_copy.rating_denominator < 10) & (tweets_df_copy.rating_denominator == 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the _text_ column using pandas `drop` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.drop('text', axis=1, inplace=True)\n",
    "# drops off text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all all values of `p1, p2 & p3` to be lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_copy[['p1', 'p2', 'p3']] = image_preds_copy[['p1', 'p2', 'p3']].apply(lambda x: x.str.lower())\n",
    "# transform all dog breeds names to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #9:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor out rows which have all `p1_dog, p2_dog & p3_dog` values as `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_copy = image_preds_copy[~((image_preds_copy.p1_dog == False) & (image_preds_copy.p2_dog == False) &(image_preds_copy.p3_dog == False))]\n",
    "#returns only true dog image records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_copy[(image_preds_copy.p1_dog == False) & (image_preds_copy.p2_dog == False) &(image_preds_copy.p3_dog == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename `id` column to `tweet_id` using pandas' `rename` method for **retweets_df**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_df_copy.rename(columns={'id': 'tweet_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_df_copy.drop(['created_at'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #11(Tidiness):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns `doggo, floofer, pupper & puppo` and make new column, `dog_stage` to represent values of all 4 dropped columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = tweets_df_copy.copy()\n",
    "df2 = tweets_df_copy.copy()\n",
    "# makes two copies of the tweets_df dataset\n",
    "\n",
    "df1 = df1[(df1['doggo'].isnull()) & (df1['floofer'].isnull()) & (df1['pupper'].isnull()) & (df1['puppo'].isnull())]\n",
    "df1.drop(['doggo','floofer','pupper','puppo'], axis=1, inplace=True)\n",
    "# df1 to contain no known dog stage\n",
    "\n",
    "dog_stage = np.empty(len(df1))\n",
    "dog_stage[:] = np.nan\n",
    "df1['dog_stage'] = dog_stage\n",
    "# creating a df1 column of an empty dog stage\n",
    "\n",
    "\n",
    "df2 = df2[(df2['doggo'].notnull()) | (df2['floofer'].notnull()) | (df2['pupper'].notnull()) | (df2['puppo'].notnull())]\n",
    "# df2 to contain at least one known dog stage\n",
    "\n",
    "df2 = pd.melt(df2, id_vars=['tweet_id', 'timestamp','source',\n",
    "                        'expanded_urls','rating_numerator',\n",
    "                        'rating_denominator','name'], value_name='dog_stage')\n",
    "# melting the 4 dog stages (doggo, floofer, pupper & puppo) into dog_stage\n",
    "\n",
    "df2.drop('variable', axis=1, inplace=True)\n",
    "df2 = df2[df2['dog_stage'].notnull()]\n",
    "df2 = df2[~((df2.tweet_id.duplicated()) & (df2.dog_stage.notnull()))]\n",
    "\n",
    "tweets_df_copy = pd.concat([df1, df2], ignore_index=True)\n",
    "# concating df1 and df2 back to give tweets_df_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #12(Tidiness):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return new column name: `dog_type` for `p1_conf or p2_conf or p3_conf` with the highest value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_dog(image):\n",
    "\n",
    "    \"\"\" \n",
    "    Compares three confidence values\n",
    "\n",
    "    Arguments:\n",
    "        image: a dataframe\n",
    "\n",
    "    Returns:\n",
    "        dog_type: column of dog breed names with highest predicted dog breed name\n",
    "    \"\"\"\n",
    "\n",
    "    if image['p1_conf'] > image['p2_conf'] > image['p3_conf'] and image['p1_dog'] == True:\n",
    "        return image['p1']\n",
    "    elif image['p2_conf'] > image['p3_conf'] and image['p2_dog'] == True:\n",
    "        return image['p2']\n",
    "    else:\n",
    "        return image['p3']\n",
    "\n",
    "image_preds_copy['dog_type'] = image_preds_copy.apply(right_dog, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_copy.drop(['p1', 'p1_conf', 'p1_dog','p2', 'p2_conf', 'p2_dog','p3', 'p3_conf', 'p3_dog'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_preds_copy.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean = pd.merge(tweets_df_copy, retweet_df_copy, on=['tweet_id'], how='left')\n",
    "twitter_df_clean = pd.merge(twitter_df_clean, image_preds_copy, on=['tweet_id'])\n",
    "twitter_df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.to_csv('twitter_archive_master.csv', index=False)\n",
    "# saving the combined dataset as a csv document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.dog_type.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('rating_numerator')['favorite_count'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('rating_numerator')['retweet_count'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('rating_numerator')['favorite_count'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('dog_type')['retweet_count'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('dog_type')['favorite_count'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('dog_stage')['rating_numerator'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('dog_stage')['retweet_count'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.groupby('dog_stage')['favorite_count'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1. The Golden retriever is the most common dog in the WeRateDog archive\n",
    "\n",
    "2. The Bedlington terrier is the most liked as well as the most retweeted dog type. Others which make this list include: French bulldog and Afghan hound\n",
    "\n",
    "3. Floofer dogs get better average numerator ratings than others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(data, color, label_x, label_y, title):\n",
    "\n",
    "    \"\"\" \n",
    "    Plots a bar plot between two correlated variables\n",
    "\n",
    "    Arguments:\n",
    "        data: a dictionary\n",
    "        color: a string\n",
    "        label_X: a string\n",
    "        label_y: a string\n",
    "\n",
    "    Returns:\n",
    "        a bar plot\n",
    "    \"\"\"\n",
    "\n",
    "    height = list(data.keys())\n",
    "    values = list(data.values())\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    plt.bar(height, values, color=color)\n",
    "    plt.xlabel(label_x, fontsize=14)\n",
    "    plt.ylabel(label_y, fontsize=14)\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.tick_params(left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df_clean.plot.scatter(x='rating_numerator', y='favorite_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floofer_df = twitter_df_clean.query('dog_stage == \"floofer\"')['rating_numerator'].mean()\n",
    "doggo_df = twitter_df_clean.query('dog_stage == \"doggo\"')['rating_numerator'].mean()\n",
    "puppo_df = twitter_df_clean.query('dog_stage == \"puppo\"')['rating_numerator'].mean()\n",
    "pupper_df = twitter_df_clean.query('dog_stage == \"pupper\"')['rating_numerator'].mean()\n",
    "\n",
    "data = {'floofer':floofer_df, 'doggo':doggo_df, 'puppo':puppo_df, 'pupper':pupper_df}\n",
    "\n",
    "plot_bar(data, color='maroon', label_x='Dog_stage', label_y='Average rating', title='Average Rating of Dog stages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'floofer':floofer_df, 'doggo':doggo_df, 'puppo':puppo_df, 'pupper':pupper_df}\n",
    "height = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(height, values)\n",
    "plt.xlabel('Dog_stage')\n",
    "plt.ylabel('Average rating')\n",
    "plt.title('Line graph of average rating of dog stages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "favourite_floffer = twitter_df_clean.query('dog_stage == \"floofer\"')['favorite_count'].mean()\n",
    "favourite_doggo = twitter_df_clean.query('dog_stage == \"doggo\"')['favorite_count'].mean()\n",
    "favourite_pupppo = twitter_df_clean.query('dog_stage == \"puppo\"')['favorite_count'].mean()\n",
    "favourite_pupper = twitter_df_clean.query('dog_stage == \"pupper\"')['favorite_count'].mean()\n",
    "\n",
    "data = {'floofer':favourite_floffer, 'doggo':favourite_doggo, 'puppo':favourite_pupppo, 'pupper':favourite_pupper}\n",
    "\n",
    "plot_bar(data, color='green', label_x='dog stage', label_y='favorite count', title='Average Favorite count of Dog Stages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_floffer = twitter_df_clean.query('dog_stage == \"floofer\"')['retweet_count'].mean()\n",
    "retweet_doggo = twitter_df_clean.query('dog_stage == \"doggo\"')['retweet_count'].mean()\n",
    "retweet_pupppo = twitter_df_clean.query('dog_stage == \"puppo\"')['retweet_count'].mean()\n",
    "retweet_pupper = twitter_df_clean.query('dog_stage == \"pupper\"')['retweet_count'].mean()\n",
    "\n",
    "data = {'floofer':retweet_floffer, 'doggo':retweet_doggo, 'puppo':retweet_pupppo, 'pupper':retweet_pupper}\n",
    "\n",
    "plot_bar(data, color='#00008b', label_x='dog stage', label_y='retweet count', title='Average Retweet count of Dog Stages')"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('new_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c676deaa78abaee0b147ebd64d7beb965edec7c2820b06e743a4e69cc81c938c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
